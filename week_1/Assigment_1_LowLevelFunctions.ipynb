{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = 'center'> Network Analysis </h1>\n",
    "<h2 align = 'center'> Individual Assignment 1 </h2>\n",
    "\n",
    "<h3 align = 'center'> LowLevel Functions </h2>\n",
    "\n",
    "<h4 align = 'center' > @ChenYu Wang - c.wang4@students.uu.nl , 6774326 </h4>\n",
    "<h4 align = 'center' > @Lena Walcher - l.t.walcher@students.uu.nl, 6774326 </h4>\n",
    "<h4 align = 'center' > @Ioannis Konstantakopoulos - i.konstantakopoulos@students.uu.nl, 6774326 </h4>\n",
    "<h4 align = 'center' > @Hans Franke - h.a.franke@students.uu.nl, 6774326 </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning relies on a few basic operations: convolution, nonlinear activation,\n",
    "pooling, and normalisation. Backpropagation of error is used to learn connection\n",
    "weights, and a fully-connected layer linked to output nodes with a softmax function\n",
    "are also required. So far, we have used calls to Keras’s high-level libraries to do\n",
    "these operations, as these are efficiently coded and easy to use. But it is also\n",
    "important that you understand the basic functions at a low level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 20:\n",
    "Write a simple function that achieves the convolution operation efficiently for twodimensional\n",
    "and three-dimensional inputs. This should allow you to input a set of\n",
    "convolutional filters (‘kernels’ in Keras’s terminology) and an input layer (or image)\n",
    "as inputs. The input layer should have a third dimension, representing a stack of\n",
    "feature maps, and each filter should have a third dimension of corresponding size.\n",
    "The function should output a number of two-dimensional feature maps\n",
    "corresponding to the number of input filters, though these can be stacked into a third\n",
    "dimensional like the input layer. After agreeing on a common function with your\n",
    "group members, show this to your teacher. (Question 20, 5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve2D(image, kernel, padding=1, strides=1):\n",
    "    # Cross Correlation\n",
    "    kernel = np.flipud(np.fliplr(kernel))\n",
    "\n",
    "    # Gather Shapes of Kernel + Image + Padding\n",
    "    xKernShape = kernel.shape[0]\n",
    "    yKernShape = kernel.shape[1]\n",
    "    xImgShape = image.shape[0]\n",
    "    yImgShape = image.shape[1]\n",
    "\n",
    "    # Shape of Output Convolution\n",
    "    xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1)\n",
    "    yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1)\n",
    "    output = np.zeros((xOutput, yOutput))\n",
    "\n",
    "    # Apply Equal Padding to All Sides\n",
    "    if padding != 0:\n",
    "        imagePadded = np.zeros((image.shape[0] + padding*2, image.shape[1] + padding*2))\n",
    "        imagePadded[int(padding):int(-1 * padding), int(padding):int(-1 * padding)] = image\n",
    "        print('Image Padded \\n', imagePadded)\n",
    "    else:\n",
    "        imagePadded = image\n",
    "\n",
    "    # Iterate through image\n",
    "    for y in range(image.shape[1]):\n",
    "        # Exit Convolution\n",
    "        if y > image.shape[1] - yKernShape:\n",
    "            break\n",
    "        # Only Convolve if y has gone down by the specified Strides\n",
    "        if y % strides == 0:\n",
    "            for x in range(image.shape[0]):\n",
    "                # Go to next row once kernel is out of bounds\n",
    "                if x > image.shape[0] - xKernShape:\n",
    "                    break\n",
    "                try:\n",
    "                    # Only Convolve if x has moved by the specified Strides\n",
    "                    if x % strides == 0:\n",
    "                        output[x, y] = (kernel * imagePadded[x: x + xKernShape, y: y + yKernShape]).sum()\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt \n",
    "from functools import reduce\n",
    "%matplotlib inline\n",
    "\n",
    "class Conv2D:\n",
    "    '''A Convolution layer using nxn filters.\n",
    "    \n",
    "    A simple function that achieves the convolution operation efficiently for two-dimensional inputs and three-dimensional inputs. \n",
    "    a set of convolutional filters (‘kernels’ in Keras’s terminology)\n",
    "    an input layer (or image) as inputs. \n",
    "\n",
    "    The input layer should have a third dimension or two dimension, \n",
    "    representing a stack of feature maps, and each filter should have a third dimension of corresponding size. \n",
    "\n",
    "    The function should output a number of two-dimensional feature maps corresponding to the number of input filters, \n",
    "    though these can be stacked into a third dimensional like the input layer. \n",
    "            \n",
    "    TODO: 3d\n",
    "    TODO: padding\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_filters, kernal_size):\n",
    "        '''\n",
    "            filters is a 3 dimensions array (num_filters, 3, 3)\n",
    "        '''\n",
    "        self.num_filters = num_filters\n",
    "        self.kernal_size = kernal_size\n",
    "        self.filters = np.random.randn(num_filters, 3, 3)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def iterate_regions(self, image):\n",
    "        '''Generates image regions    \n",
    "        ''' \n",
    "        h, w = image.shape\n",
    "\n",
    "        for i in range(h - 2):\n",
    "            for j in range(w - 2):\n",
    "                im_region = image[i:(i + self.kernal_size), j:(j + self.kernal_size)]\n",
    "                yield im_region, i, j\n",
    "\n",
    "    def sub_forward(self, inputs):\n",
    "        '''Return a 3 dimensions array\n",
    "            \n",
    "        ::inputs: 28x28\n",
    "        ::outputs: 26x26x8\n",
    "        '''\n",
    "        # (28, 28)\n",
    "        h, w = inputs.shape\n",
    "\n",
    "        # for now, padding = 0 and stride = 1 \n",
    "        outputs = np.zeros((h - self.kernal_size + 1, w - self.kernal_size + 1, self.num_filters))\n",
    "    \n",
    "        for im_region, i, j in self.iterate_regions(inputs):\n",
    "            outputs[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n",
    "        return outputs  \n",
    "    \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        if len(inputs.shape) == 2:\n",
    "            return self.sub_forward(inputs)\n",
    "        \n",
    "        elif len(inputs.shape) == 3:\n",
    "            permuted = np.transpose(inputs, (2, 0, 1))\n",
    "            c, h, w = permuted.shape\n",
    "            \n",
    "            container = np.zeros((h - self.kernal_size + 1, w - self.kernal_size + 1, self.num_filters))\n",
    "\n",
    "            for i in range(c):\n",
    "                outputs = self.sub_forward(permuted[i])\n",
    "                container += outputs\n",
    "            return container     \n",
    "        else:\n",
    "            raise AttributeError\n",
    "\n",
    "\n",
    "class Activation:\n",
    "    '''Activation function Implement\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def relu(self, in_features):\n",
    "        '''A simple function that achieves rectified linear (relu) activation over a whole feature map, with a threshold at zero. \n",
    "\n",
    "        in_features can be numpy array, scalar, vector, or matrix\n",
    "        '''\n",
    "        return np.maximum(0, in_features)\n",
    "\n",
    "    def sigmoid(self, in_features):\n",
    "        '''Apply sigmoid activation function\n",
    "        \n",
    "        in_features can be numpy array, scalar, vector, or matrix\n",
    "        '''\n",
    "        return 1/(1+np.exp(-in_features))\n",
    "    \n",
    "    def leakyRelu(self, in_features, alpha=0.1):\n",
    "        '''Apply leakyRelu activation function\n",
    "        \n",
    "        in_features can be numpy array, scalar, vector, or matrix\n",
    "        '''\n",
    "        return np.where(in_features > 0, in_features, in_features * alpha)      \n",
    "    \n",
    "    def softmax(self, in_features):\n",
    "        '''A function that converts the activation of a 1-dimensional matrix (such as the output of a fully-connected layer) \n",
    "        into a set of probabilities that each matrix element is the most likely classification. \n",
    "\n",
    "        This should include the algorithmic expression of a softmax (normalised exponential) function.\n",
    "        \n",
    "        in_features can be numpy array, scalar, vector, or matrix\n",
    "        '''\n",
    "        expo = np.exp(in_features)\n",
    "        expo_sum = np.sum(expo)\n",
    "        return expo/expo_sum\n",
    "\n",
    "    \n",
    "class MaxPooling:\n",
    "    '''Specify the spatial extent of the pooling, with the size of the output feature map changing accordingly\n",
    "    '''\n",
    "    def __init__(self, pool=2, stride=2):\n",
    "        self.pool = pool \n",
    "        self.stride = stride \n",
    "\n",
    "    def iterate_regions(self, image):\n",
    "        '''Generates non-overlapping kxk image regions to pool over\n",
    "        '''\n",
    "        h, w, c = image.shape\n",
    "        \n",
    "        # floor() the value\n",
    "        new_h = int(np.floor(h/self.pool))\n",
    "        new_w = int(np.floor(w/self.pool))\n",
    "                \n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                im_region = image[(i * self.pool):(i * self.pool + self.stride), (j * self.pool):(j * self.pool + self.stride)]\n",
    "                yield im_region, i, j\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''Apply a forward for the maxpooling layer\n",
    "        \n",
    "        ::output is a 3d numpy array with dimensions (floor(h/2), floor(w/2), num_filters).\n",
    "        ::input is a 3d numpy array with dimensions (h, w, num_filters)\n",
    "        '''\n",
    "        h, w, num_filters = inputs.shape\n",
    "        \n",
    "        # floor() the value\n",
    "        new_h = int(np.floor(h/self.pool))\n",
    "        new_w = int(np.floor(w/self.pool))\n",
    "        \n",
    "        output = np.zeros((new_h, new_w, num_filters))\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(inputs):\n",
    "            output[i, j] = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "        return output\n",
    "    \n",
    "\n",
    "class Normalization():\n",
    "    '''Normalization Implement\n",
    "    \n",
    "    TODO: for all filter or overall?\n",
    "    '''\n",
    "    def __init__(slef):\n",
    "        self.epsilon = np.finfo(float).eps\n",
    "        # self.epsilon=1e-10\n",
    "        \n",
    "    \n",
    "    def zeromean(self,in_features):\n",
    "        '''Normalisation within each feature map, modifying the feature map \n",
    "        so that its mean value is zero and its standard deviation is one.\n",
    "        '''\n",
    "        return (in_features - np.mean(in_features, axis=0))/ ( np.std(in_features, axis=0)+ self.epsilon )\n",
    "    \n",
    "    def minmax(self,in_features):\n",
    "        '''min-max normalization\n",
    "        '''\n",
    "        return (in_features - np.amin(in_features, axis=0)) / (np.amax(in_features, axis=0)-np.amin(in_features, axis=0) + self.epsilon)\n",
    "    \n",
    "    def loge(self,in_features):\n",
    "        '''log transform normalization\n",
    "        \n",
    "        note: np.log is ln, whereas np.log10 is standard base 10 log.\n",
    "        '''\n",
    "        return np.log(in_features)/np.log(np.amax(in_features, axis=0))\n",
    "    \n",
    "    def log10(self,in_features):\n",
    "        '''log transform normalization\n",
    "        \n",
    "        note: np.log is ln, whereas np.log10 is standard base 10 log.\n",
    "        '''\n",
    "        return np.log10(in_features)/np.log10(np.amax(in_features, axis=0))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class FC:\n",
    "    '''fully-connected layer\n",
    "    specify the number of output nodes, and link each of these to every node a stack of feature maps. \n",
    "    the stack of feature maps will typically be flattened into a 1-dimensional matrix first. \n",
    "    '''\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        '''Divide by in_dim to reduce the variance of our initial values\n",
    "        \n",
    "        in_dim = Inputs Numbers of Neuron\n",
    "        out_dim = Outputs Numbers of Neuron\n",
    "        '''\n",
    "        self.weights = np.random.randn(in_dim, out_dim) / in_dim\n",
    "        self.biases = np.zeros(out_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''Returns a 1d numpy array\n",
    "        '''\n",
    "        inputs = inputs.flatten()\n",
    "\n",
    "        in_dim, out_dim = self.weights.shape\n",
    "\n",
    "        \n",
    "        outputs = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "    '''A standard fully-connected layer with softmax activation.\n",
    "    \n",
    "    Refer https://deepai.org/machine-learning-glossary-and-terms/softmax-layer\n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        '''Divide by in_dim to reduce the variance of our initial values\n",
    "        \n",
    "        in_dim = Inputs Numbers of Neuron\n",
    "        out_dim = Outputs Numbers of Neuron\n",
    "        '''\n",
    "\n",
    "        self.weights = np.random.randn(in_dim, out_dim) / in_dim\n",
    "        self.biases = np.zeros(out_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        Performs a forward pass of the softmax layer using the given input.\n",
    "        Returns a 1d numpy array containing the respective probability values.\n",
    "        - input can be any array with any dimensions.\n",
    "        '''\n",
    "        inputs = inputs.flatten()\n",
    "\n",
    "        in_dim, out_dim = self.weights.shape\n",
    "\n",
    "        feature = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "        # softmax function\n",
    "        expo = np.exp(feature)\n",
    "        expo_sum = np.sum(expo, axis=0)\n",
    "        out = expo / expo_sum\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "class clac:\n",
    "    '''write some utility funtion \n",
    "    '''\n",
    "    def count_dimension(inputs):\n",
    "        '''count dimention\n",
    "        '''\n",
    "        return reduce(lambda x,y:x*y,inputs.shape)\n",
    "        \n",
    "    \n",
    "# numpy.maximum\n",
    "# Element-wise maximum of array elements.\n",
    "\n",
    "# amax\n",
    "# The maximum value of an array along a given axis, propagates NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.array([[-1, 1],[-1, 1]\n",
    "                 \n",
    "                  ])\n",
    "\n",
    "\n",
    "array_1 = np.array([[1,0,1],[1,0,1]])\n",
    "array_2 =  np.array([[[ 0.,  0.,  0.,  0.],\n",
    "                      [ 0.,  1.,  0.,  0.],\n",
    "                      [ 0.,  0.,  0.,  0.]],\n",
    "\n",
    "                      [[ 0.,  0.,  0.,  0.],\n",
    "                      [ 0.,  1.,  0.,  0.],\n",
    "                      [ 0.,  0.,  0.,  0.]]])\n",
    "kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  1],\n",
       "       [-1,  1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2., -2.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve2D(array_1, kernel, padding=0, strides=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape (50000, 32, 32, 3)\n",
      "x test shape (10000, 32, 32, 3)\n",
      "y train shape: (50000, 10)\n",
      "y test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255  # (50000, 32, 32, 3)\n",
    "x_test = x_test.astype(\"float32\") / 255 # (10000, 32, 32, 3)\n",
    "\n",
    "# Need an extra dimension for colour channels\n",
    "print(\"x train shape\", x_train.shape)\n",
    "print(\"x test shape\", x_test.shape)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes) # (50000, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes) # (10000, 10)\n",
    "\n",
    "print(\"y train shape:\", y_train.shape)\n",
    "print(\"y test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "image = x_train[0]\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 30, 8)\n",
      "(30, 30, 8)\n"
     ]
    }
   ],
   "source": [
    "#Check Convolution\n",
    "conv = Conv2D(num_filters=8, kernal_size=3)\n",
    "output = conv.forward(image)\n",
    "print(output.shape)\n",
    "\n",
    "image_reduce = image[:,:,0]\n",
    "output_2d = conv.forward(image_reduce)\n",
    "print(output_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 15, 8)\n"
     ]
    }
   ],
   "source": [
    "#Check Max Pooling\n",
    "maxpool = MaxPooling()\n",
    "output = maxpool.forward(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "#Check FC Layer\n",
    "output = FC(in_dim=clac.count_dimension(output), out_dim=10).forward(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "#Check Softmax\n",
    "output = Softmax(in_dim=clac.count_dimension(output), out_dim=10).forward(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 21:\n",
    "Write a simple function that achieves rectified linear (relu) activation over a whole\n",
    "feature map, with a threshold at zero. After agreeing on a common function with your\n",
    "group members, show this to your teacher. (Question 21, 2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 22:\n",
    "Write a simple function that achieves max pooling. This should allow you to specify\n",
    "the spatial extent of the pooling, with the size of the output feature map changing\n",
    "accordingly. After agreeing on a common function with your group members, show\n",
    "this to your teacher. (Question 22, 3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 23:\n",
    "Write a simple function that achieves normalisation within each feature map,\n",
    "modifying the feature map so that its mean value is zero and its standard deviation is\n",
    "one. After agreeing on a common function with your group members, show this to\n",
    "your teacher. (Question 23, 2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 24:\n",
    "Write a function that produces a fully-connected layer. This should allow you to\n",
    "specify the number of output nodes, and link each of these to every node a stack of\n",
    "feature maps. The stack of feature maps will typically be flattened into a 1-\n",
    "dimensional matrix first. After agreeing on a common function with your group\n",
    "members, show this to your teacher. (Question 24, 5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 25:\n",
    "Write a function that converts the activation of a 1-dimensional matrix (such as the\n",
    "output of a fully-connected layer) into a set of probabilities that each matrix element\n",
    "is the most likely classification. This should include the algorithmic expression of a\n",
    "softmax (normalised exponential) function. After agreeing on a common function with\n",
    "your group members, show this to your teacher. (Question 25, 2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS QUESTION:** Write a function to achieve backpropagation of error to affect\n",
    "the convolutional filter (kernel) structure used in Question 20. Modify your function\n",
    "from Question 20 so you can input the convolutional filters, allowing you to modify\n",
    "these filters using backpropagation (outside the convolution function). Initialise the\n",
    "network with random weights in the filters. After agreeing on common functions for\n",
    "convolution with your group members, show your teacher how you changed this from\n",
    "the answer given in Question 20. Show your teacher your code for backpropagation\n",
    "(Question 26, 5 points)\n",
    "\n",
    "**BONUS QUESTION:** Write a piece of code that uses all of these functions (from\n",
    "Questions 22-28) together to make a convolutional neural network with two\n",
    "convolutional layers, a fully connected layer, and an output layer (pooling is optional,\n",
    "but thresholding and normalisation are required). This should give the accuracy of\n",
    "the labels as an output. Show the resulting code to your teacher. (Question 27, 5\n",
    "points)\n",
    "\n",
    "\n",
    "**BONUS QUESTION:** Use the resulting function to learn to classify the mnist data\n",
    "set, as you did in question 10. Plot the progression of the classification accuracy\n",
    "over 100 cycles. Show the resulting plots to your teacher. (Question 28, 5 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

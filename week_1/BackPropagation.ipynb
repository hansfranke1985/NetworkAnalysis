{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(X, W):\n",
    "    '''\n",
    "    The forward computation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    X -- output activations of the previous layer, numpy array of shape (n_H_prev, n_W_prev) assuming input channels = 1\n",
    "    W -- Weights, numpy array of size (f, f) assuming number of filters = 1\n",
    "    \n",
    "    Returns:\n",
    "    H -- conv output, numpy array of size (n_H, n_W)\n",
    "    cache -- cache of values needed for conv_backward() function\n",
    "    '''\n",
    "    \n",
    "    # Retrieving dimensions from X's shape\n",
    "    (n_H_prev, n_W_prev) = X.shape\n",
    "    \n",
    "    # Retrieving dimensions from W's shape\n",
    "    (f, f) = W.shape\n",
    "    \n",
    "    # Compute the output dimensions assuming no padding and stride = 1\n",
    "    n_H = n_H_prev - f + 1\n",
    "    n_W = n_W_prev - f + 1\n",
    "    \n",
    "    # Initialize the output H with zeros\n",
    "    H = np.zeros((n_H, n_W))\n",
    "    \n",
    "    # Looping over vertical(h) and horizontal(w) axis of output volume\n",
    "    for h in range(n_H):\n",
    "        for w in range(n_W):\n",
    "            x_slice = X[h:h+f, w:w+f]\n",
    "            H[h,w] = np.sum(x_slice * W)\n",
    "            \n",
    "    # Saving information in 'cache' for backprop\n",
    "    cache = (X, W)\n",
    "    \n",
    "    return H, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dH, cache):\n",
    "    '''\n",
    "    The backward computation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    dH -- gradient of the cost with respect to output of the conv layer (H), numpy array of shape (n_H, n_W) assuming channels = 1\n",
    "    cache -- cache of values needed for the conv_backward(), output of conv_forward()\n",
    "    \n",
    "    Returns:\n",
    "    dX -- gradient of the cost with respect to input of the conv layer (X), numpy array of shape (n_H_prev, n_W_prev) assuming channels = 1\n",
    "    dW -- gradient of the cost with respect to the weights of the conv layer (W), numpy array of shape (f,f) assuming single filter\n",
    "    '''\n",
    "    \n",
    "    # Retrieving information from the \"cache\"\n",
    "    (X, W) = cache\n",
    "    \n",
    "    # Retrieving dimensions from X's shape\n",
    "    (n_H_prev, n_W_prev) = X.shape\n",
    "    \n",
    "    # Retrieving dimensions from W's shape\n",
    "    (f, f) = W.shape\n",
    "    \n",
    "    # Retrieving dimensions from dH's shape\n",
    "    (n_H, n_W) = dH.shape\n",
    "    \n",
    "    # Initializing dX, dW with the correct shapes\n",
    "    dX = np.zeros(X.shape)\n",
    "    dW = np.zeros(W.shape)\n",
    "    \n",
    "    # Looping over vertical(h) and horizontal(w) axis of the output\n",
    "    for h in range(n_H):\n",
    "        for w in range(n_W):\n",
    "            dX[h:h+f, w:w+f] += W * dH(h,w)\n",
    "            dW += X[h:h+f, w:w+f] * dH(h,w)\n",
    "    \n",
    "    return dX, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "[[1 2]\n",
      " [4 5]]\n",
      "\n",
      "\n",
      "(2, 2)\n",
      "[[1 0]\n",
      " [1 0]]\n",
      "\n",
      "\n",
      "(2, 2)\n",
      "[[3 0]\n",
      " [9 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#input\n",
    "X = np.array([[1,2],[4,5]])\n",
    "print(X.shape)\n",
    "print(X)\n",
    "print(\"\\n\")\n",
    "#filter\n",
    "W = np.array([[1,0],[1,0]])\n",
    "print(W.shape)\n",
    "print(W)\n",
    "print(\"\\n\")\n",
    "#product\n",
    "P = np.dot(X,W)\n",
    "print(P.shape)\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0],\n",
       "       [9, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#product\n",
    "P = np.dot(X,W)\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.]]\n",
      "\n",
      "\n",
      "(array([[1, 2],\n",
      "       [4, 5]]), array([[1, 0],\n",
      "       [1, 0]]))\n"
     ]
    }
   ],
   "source": [
    "H, cache = conv_forward(X,W)\n",
    "print(H)\n",
    "print(\"\\n\")\n",
    "print(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-f8a5a842bec9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconv_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-f6b1a16f2003>\u001b[0m in \u001b[0;36mconv_backward\u001b[1;34m(dH, cache)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_H\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_W\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mdX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mW\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdH\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mdW\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdH\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "conv_backward(P,cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random starting input to hidden weights: \n",
      "[[0.77132064 0.02075195 0.63364823 0.74880388]\n",
      " [0.49850701 0.22479665 0.19806286 0.76053071]\n",
      " [0.16911084 0.08833981 0.68535982 0.95339335]]\n",
      "Random starting hidden to output weights: \n",
      "[[0.00394827]\n",
      " [0.51219226]\n",
      " [0.81262096]\n",
      " [0.61252607]]\n",
      "The final prediction from neural network are: \n",
      "[[0.00572029]\n",
      " [0.99442052]\n",
      " [0.99527493]\n",
      " [0.00467507]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        np.random.seed(10) # for generating the same results\n",
    "        self.wij   = np.random.rand(3,4) # input to hidden layer weights\n",
    "        self.wjk   = np.random.rand(4,1) # hidden layer to output weights\n",
    "        \n",
    "    def sigmoid(self, x, w):\n",
    "        z = np.dot(x, w)\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    \n",
    "    def sigmoid_derivative(self, x, w):\n",
    "        return self.sigmoid(x, w) * (1 - self.sigmoid(x, w))\n",
    "    \n",
    "    def gradient_descent(self, x, y, iterations):\n",
    "        for i in range(iterations):\n",
    "            Xi = x\n",
    "            Xj = self.sigmoid(Xi, self.wij)\n",
    "            yhat = self.sigmoid(Xj, self.wjk)\n",
    "            # gradients for hidden to output weights\n",
    "            g_wjk = np.dot(Xj.T, (y - yhat) * self.sigmoid_derivative(Xj, self.wjk))\n",
    "            # gradients for input to hidden weights\n",
    "            g_wij = np.dot(Xi.T, np.dot((y - yhat) * self.sigmoid_derivative(Xj, self.wjk), self.wjk.T) * self.sigmoid_derivative(Xi, self.wij))\n",
    "            # update weights\n",
    "            self.wij += g_wij\n",
    "            self.wjk += g_wjk\n",
    "        print('The final prediction from neural network are: ')\n",
    "        print(yhat)\n",
    "if __name__ == '__main__':\n",
    "    neural_network = NeuralNetwork()\n",
    "    print('Random starting input to hidden weights: ')\n",
    "    print(neural_network.wij)\n",
    "    print('Random starting hidden to output weights: ')\n",
    "    print(neural_network.wjk)\n",
    "    X = np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "    y = np.array([[0, 1, 1, 0]]).T\n",
    "    neural_network.gradient_descent(X, y, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
